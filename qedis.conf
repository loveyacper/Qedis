# Qedis configuration file example

# By default Qedis does not run as a daemon. Use 'yes' if you need it.
daemonize no

# Write your extensions use module, the modules will load at startup
# or your can use module load command to load module at runtime.
# On linux, you should change suffix from "dylib" to "so"
loadmodule libqedismodule.dylib
loadmodule libnotexist.dylib # a lib not exist, load raise error 

# Accept connections on the specified port, default is 6379.
# port 0 is not permitted.
port 6379

# If you want you can bind a single interface, if the bind option is not
# specified all the interfaces will listen for incoming connections.
#
# bind 127.0.0.1


# Close the connection after a client is idle for N seconds (0 to disable)
timeout 0

# Specify the server verbosity level.
# This can be one of:
# debug (a lot of information, useful for development/testing)
# verbose (many rarely useful info, but not a mess like the debug level)
# notice (moderately verbose, what you want in production probably)
# warning (only very important / critical messages are logged)
loglevel warning

# Specify the log file name. Also 'stdout' can be used to force
# Redis to log on the standard output. Note that if you use standard
# output for logging but daemonize, logs will be sent to /dev/null
logfile stdout

# Set the number of databases. The default database is DB 0, you can select
# a different one on a per-connection basis using SELECT <dbid> where
# dbid is a number between 0 and 'databases'-1
databases 1

################################ SNAPSHOTTING  #################################
#
# Save the DB on disk:
#
#   save <seconds> <changes>
#
#   Will save the DB if both the given number of seconds and the given
#   number of write operations against the DB occurred.
#
#   In the example below the behaviour will be to save:
#   after 900 sec (15 min) if at least 1 key changed
#   after 300 sec (5 min) if at least 10 keys changed
#   after 60 sec if at least 10000 keys changed
#
#   Note: you can disable saving at all commenting all the "save" lines.
#
#   It is also possible to remove all the previously configured save
#   points by adding a save directive with a single empty string argument
#   like in the following example:
#
save ""

#save 900 1
#save 300 10
#save 60000 1000000

# By default Redis will stop accepting writes if RDB snapshots are enabled
# (at least one save point) and the latest background save failed.
# This will make the user aware (in an hard way) that data is not persisting
# on disk properly, otherwise chances are that no one will notice and some
# distater will happen.
#
# If the background saving process will start working again Redis will
# automatically allow writes again.
#
# However if you have setup your proper monitoring of the Redis server
# and persistence, you may want to disable this feature so that Redis will
# continue to work as usually even if there are problems with disk,
# permissions, and so forth.
stop-writes-on-bgsave-error yes # not support

# Compress string objects using LZF when dump .rdb databases?
# For default that's set to 'yes' as it's almost always a win.
# If you want to save some CPU in the saving child set it to 'no' but
# the dataset will likely be bigger if you have compressible values or keys.
rdbcompression yes # Qedis always use compression for rdb file

# Since version 5 of RDB a CRC64 checksum is placed at the end of the file.
# This makes the format more resistant to corruption but there is a performance
# hit to pay (around 10%) when saving and loading RDB files, so you can disable it
# for maximum performances.
#
# RDB files created with checksum disabled have a checksum of zero that will
# tell the loading code to skip the check.
rdbchecksum yes # Qedis always check sum for rdb file

# The filename where to dump the DB
dbfilename dump.rdb

# The working directory.
#
# The DB will be written inside this directory, with the filename specified
# above using the 'dbfilename' configuration directive.
# 
# The Append Only File will also be created inside this directory.
# 
# Note that you must specify a directory here, not a file name.
dir ./

################################# REPLICATION #################################

# Master-Slave replication. Use slaveof to make a Redis instance a copy of
# another Redis server. Note that the configuration is local to the slave
# so for example it is possible to configure the slave to save the DB with a
# different interval, or to listen to another port, and so on.
#
# slaveof <masterip> <masterport>
# slaveof 127.0.0.1 6379

# If the master is password protected (using the "requirepass" configuration
# directive below) it is possible to tell the slave to authenticate before
# starting the replication synchronization process, otherwise the master will
# refuse the slave request.
#
# masterauth foobar

# When a slave loses its connection with the master, or when the replication
# is still in progress, the slave can act in two different ways:
#
# 1) if slave-serve-stale-data is set to 'yes' (the default) the slave will
#    still reply to client requests, possibly with out of date data, or the
#    data set may just be empty if this is the first synchronization.
#
# 2) if slave-serve-stale-data is set to 'no' the slave will reply with
#    an error "SYNC with master in progress" to all the kind of commands
#    but to INFO and SLAVEOF.
#
# slave-serve-stale-data yes # not support yet

# You can configure a slave instance to accept writes or not. Writing against
# a slave instance may be useful to store some ephemeral data (because data
# written on a slave will be easily deleted after resync with the master) but
# may also cause problems if clients are writing to it because of a
# misconfiguration.
#
# Since Redis 2.6 by default slaves are read-only.
#
# Note: read only slaves are not designed to be exposed to untrusted clients
# on the internet. It's just a protection layer against misuse of the instance.
# Still a read only slave exports by default all the administrative commands
# such as CONFIG, DEBUG, and so forth. To a limited extend you can improve
# security of read only slaves using 'rename-command' to shadow all the
# administrative / dangerous commands.
slave-read-only yes # Qedis always set slave read only

# Slaves send PINGs to server in a predefined interval. It's possible to change
# this interval with the repl_ping_slave_period option. The default value is 10
# seconds.
#
# repl-ping-slave-period 10

# The following option sets a timeout for both Bulk transfer I/O timeout and
# master data or ping response timeout. The default value is 60 seconds.
#
# It is important to make sure that this value is greater than the value
# specified for repl-ping-slave-period otherwise a timeout will be detected
# every time there is low traffic between the master and the slave.
#
# repl-timeout 60

# The slave priority is an integer number published by Redis in the INFO output.
# It is used by Redis Sentinel in order to select a slave to promote into a
# master if the master is no longer working correctly.
#
# A slave with a low priority number is considered better for promotion, so
# for instance if there are three slaves with priority 10, 100, 25 Sentinel will
# pick the one wtih priority 10, that is the lowest.
#
# However a special priority of 0 marks the slave as not able to perform the
# role of master, so a slave with priority of 0 will never be selected by
# Redis Sentinel for promotion.
#
# By default the priority is 100.
slave-priority 100 # not support yet

################################## SECURITY ###################################

# Require clients to issue AUTH <PASSWORD> before processing any other
# commands.  This might be useful in environments in which you do not trust
# others with access to the host running redis-server.
#
# This should stay commented out for backward compatibility and because most
# people do not need auth (e.g. they run their own servers).
# 
# Warning: since Redis is pretty fast an outside user can try up to
# 150k passwords per second against a good box. This means that you should
# use a very strong password otherwise it will be very easy to break.
#
#requirepass foobar

# Command renaming.
#
# It is possible to change the name of dangerous commands in a shared
# environment. For instance the CONFIG command may be renamed into something
# hard to guess so that it will still be available for internal-use tools
# but not available for general clients.
#
# Example:
#
# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52
#
# It is also possible to completely kill a command by renaming it into
# an empty string:
#
# rename-command CONFIG ""
#
# Please note that changing the name of commands that are logged into the
# AOF file or transmitted to slaves may cause problems.

################################### LIMITS ####################################

# Set the max number of connected clients at the same time. By default
# this limit is set to 10000 clients, however if the Redis server is not
# able to configure the process file limit to allow for the specified limit
# the max number of allowed clients is set to the current file limit
# minus 32 (as Redis reserves a few file descriptors for internal uses).
#
# Once the limit is reached Redis will close all the new connections sending
# an error 'max number of clients reached'.
#
# maxclients 10000

# Don't use more memory than the specified amount of bytes.
# When the memory limit is reached Redis will try to remove keys
# accordingly to the eviction policy selected (see maxmemmory-policy).
#
# If Redis can't remove keys according to the policy, or if the policy is
# set to 'noeviction', Redis will start to reply with errors to commands
# that would use more memory, like SET, LPUSH, and so on, and will continue
# to reply to read-only commands like GET.
#
maxmemory 999999999999
#
# MAXMEMORY POLICY: how Qedis will select what to remove when maxmemory
# is reached. You can select among five behaviors:
# 
# allkeys-lru -> remove any key accordingly to the LRU algorithm
# noeviction -> don't expire at all, just return an error on write operations
# The default is:
#
maxmemory-policy noeviction

# LRU and minimal TTL algorithms are not precise algorithms but approximated
# algorithms (in order to save memory), so you can select as well the sample
# size to check. For instance for default Qedis will check 5 keys and
# pick the one that was used less recently, you can change the sample size
# using the following configuration directive.
#
maxmemory-samples 5


############################## APPEND ONLY MODE ###############################

# By default Redis asynchronously dumps the dataset on disk. This mode is
# good enough in many applications, but an issue with the Redis process or
# a power outage may result into a few minutes of writes lost (depending on
# the configured save points).
#
# The Append Only File is an alternative persistence mode that provides
# much better durability. For instance using the default data fsync policy
# (see later in the config file) Redis can lose just one second of writes in a
# dramatic event like a server power outage, or a single write if something
# wrong with the Redis process itself happens, but the operating system is
# still running correctly.
#
# AOF and RDB persistence can be enabled at the same time without problems.
# If the AOF is enabled on startup Redis will load the AOF, that is the file
# with the better durability guarantees.
#
# Please check http://redis.io/topics/persistence for more information.

appendonly no

# The name of the append only file (default: "appendonly.aof")
# appendfilename appendonly.aof

# The fsync() call tells the Operating System to actually write data on disk
# instead to wait for more data in the output buffer. Some OS will really flush 
# data on disk, some other OS will just try to do it ASAP.
#
# Redis supports three different modes:
#
# no: don't fsync, just let the OS flush the data when it wants. Faster.
# always: fsync after every write to the append only log . Slow, Safest.
# everysec: fsync only one time every second. Compromise.
#
# The default is "everysec", as that's usually the right compromise between
# speed and data safety. It's up to you to understand if you can relax this to
# "no" that will let the operating system flush the output buffer when
# it wants, for better performances (but if you can live with the idea of
# some data loss consider the default persistence mode that's snapshotting),
# or on the contrary, use "always" that's very slow but a bit safer than
# everysec.
#
# More details please check the following article:
# http://antirez.com/post/redis-persistence-demystified.html
#
# If unsure, use "everysec".

# appendfsync always
#appendfsync everysec
appendfsync no # Qedis use mmap and msync

# When the AOF fsync policy is set to always or everysec, and a background
# saving process (a background save or AOF log background rewriting) is
# performing a lot of I/O against the disk, in some Linux configurations
# Redis may block too long on the fsync() call. Note that there is no fix for
# this currently, as even performing fsync in a different thread will block
# our synchronous write(2) call.
#
# In order to mitigate this problem it's possible to use the following option
# that will prevent fsync() from being called in the main process while a
# BGSAVE or BGREWRITEAOF is in progress.
#
# This means that while another child is saving, the durability of Redis is
# the same as "appendfsync none". In practical terms, this means that it is
# possible to lose up to 30 seconds of log in the worst scenario (with the
# default Linux settings).
# 
# If you have latency problems turn this to "yes". Otherwise leave it as
# "no" that is the safest pick from the point of view of durability.
no-appendfsync-on-rewrite no

# Automatic rewrite of the append only file.
# Redis is able to automatically rewrite the log file implicitly calling
# BGREWRITEAOF when the AOF log size grows by the specified percentage.
# 
# This is how it works: Redis remembers the size of the AOF file after the
# latest rewrite (if no rewrite has happened since the restart, the size of
# the AOF at startup is used).
#
# This base size is compared to the current size. If the current size is
# bigger than the specified percentage, the rewrite is triggered. Also
# you need to specify a minimal size for the AOF file to be rewritten, this
# is useful to avoid rewriting the AOF file even if the percentage increase
# is reached but it is still pretty small.
#
# Specify a percentage of zero in order to disable the automatic AOF
# rewrite feature.

#auto-aof-rewrite-percentage 100
#auto-aof-rewrite-min-size 64mb

################################ LUA SCRIPTING  ###############################

# Max execution time of a Lua script in milliseconds.
#
# If the maximum execution time is reached Redis will log that a script is
# still in execution after the maximum allowed time and will start to
# reply to queries with an error.
#
# When a long running script exceed the maximum execution time only the
# SCRIPT KILL and SHUTDOWN NOSAVE commands are available. The first can be
# used to stop a script that did not yet called write commands. The second
# is the only way to shut down the server in the case a write commands was
# already issue by the script but the user don't want to wait for the natural
# termination of the script.
#
# Set it to 0 or a negative value for unlimited execution without warnings.
#lua-time-limit 5000

################################## SLOW LOG ###################################

# The Redis Slow Log is a system to log queries that exceeded a specified
# execution time. The execution time does not include the I/O operations
# like talking with the client, sending the reply and so forth,
# but just the time needed to actually execute the command (this is the only
# stage of command execution where the thread is blocked and can not serve
# other requests in the meantime).
# 
# You can configure the slow log with two parameters: one tells Redis
# what is the execution time, in microseconds, to exceed in order for the
# command to get logged, and the other parameter is the length of the
# slow log. When a new command is logged the oldest one is removed from the
# queue of logged commands.

# The following time is expressed in microseconds, so 1000000 is equivalent
# to one second. Note that a negative number disables the slow log, while
# a value of zero forces the logging of every command.
slowlog-log-slower-than 10000

# There is no limit to this length. Just be aware that it will consume memory.
# You can reclaim memory used by the slow log with SLOWLOG RESET.
slowlog-max-len 128

############################### ADVANCED CONFIG ###############################

# Redis calls an internal function to perform many background tasks, like
# closing connections of clients in timeot, purging expired keys that are
# never requested, and so forth.
#
# Not all tasks are perforemd with the same frequency, but Redis checks for
# tasks to perform accordingly to the specified "hz" value.
#
# By default "hz" is set to 10. Raising the value will use more CPU when
# Redis is idle, but at the same time will make Redis more responsive when
# there are many keys expiring at the same time, and timeouts may be
# handled with more precision.
#
# The range is between 1 and 500, however a value over 100 is usually not
# a good idea. Most users should use the default of 10 and raise this up to
# 100 only in environments where very low latency is required.
hz 10
############################### BACKENDS CONFIG ###############################
# Qedis is a in memory database, though it has aof and rdb for dump data to disk, it
# is very limited. Try use leveldb for real storage, qedis as cache. The cache algorithm
# is like linux page cache, please google or read your favorite linux book
# 0 is default, no backend
# 1 is leveldb
# 2 is rocksdb

backend 2
backendpath dump
# the frequency of dump to backend per second
backendhz 10

############################### CLUSTER CONFIG ###############################
#
cluster off

# the cluster center, may be zookeeper or etcd 
clustercenters 127.0.0.1:52181;127.0.0.1:2181

# which set this instance belong to
# may be many instances in the same setid, but only one can be master, others are slaves
setid 1

############################## ROCKSDB CONFIG ###############################\

#   Parameters that affect performance
#   Amount of data to build up in memory (backed by an unsorted log
#   on disk) before converting to a sorted on-disk file.
#   Larger values increase performance, especially during bulk loads.
#   Up to max_write_buffer_number write buffers may be held in memory
#   at the same time,
#   so you may wish to adjust this parameter to control memory usage.
#   Also, a larger write buffer will result in a longer recovery time
#   the next time the database is opened.
#   Note that write_buffer_size is enforced per column family.
#   See db_write_buffer_size for sharing memory across column families.
#   Default: 64MB
#   Dynamically changeable through SetOptions() API
write_buffer_size 134217728

#   Number of files to trigger level-0 compaction. A value <0 means that
#   level-0 compaction will not be triggered by number of files at all.
#   Default: 4
#   Dynamically changeable through SetOptions() API
level0_file_num_compaction_trigger 4

#   Soft limit on number of level-0 files. We start slowing down writes at this
#   point. A value <0 means that no writing slow down will be triggered by
#   number of files in level-0.
#   Default: 20
#   Dynamically changeable through SetOptions() API
level0_slowdown_writes_trigger 20

#   Maximum number of level-0 files.  We stop writes at this point.
#   Default: 36
#   Dynamically changeable through SetOptions() API
level0_stop_writes_trigger 36

#   The maximum number of write buffers that are built up in memory.
#   The default and the minimum number is 2, so that when 1 write buffer
#   is being flushed to storage, new writes can continue to the other
#   write buffer.
#   If max_write_buffer_number > 3, writing will be slowed down to
#   options.delayed_write_rate if we are writing to the last write buffer
#   allowed.
#   Default: 2
#   Dynamically changeable through SetOptions() API
max_write_buffer_number 4

#   The minimum number of write buffers that will be merged together
#   before writing to storage.  If set to 1, then
#   all write buffers are flushed to L0 as individual files and this increases
#   read amplification because a get request has to check in all of these
#   files. Also, an in-memory merge may result in writing lesser
#   data to storage if there are duplicate records in each of these
#   individual write buffers.  Default: 1
min_write_buffer_number_to_merge 2

## Maximum number of threads of RocksDB background jobs.
## The background tasks include compaction and flush. For detailed information why RocksDB needs to
## do compaction, see RocksDB-related materials. RocksDB will adjust flush and compaction threads
## according to the formula:
##   max_flushes = max_flushes = max(1, max_background_jobs / 4)
##   max_compactions = max(1, max_background_jobs - max_flushes)
## When write traffic (like the importing data size)  is big, it is recommended to enable more
## threads. But set the number of the enabled threads  smaller than that of CPU cores. For example,
## when importing data, for a machine with a 32-core CPU, set the value to 28.
## The default value is set to 8 or CPU_NUM - 1, whichever is smaller.
max_background_jobs 2

## Represents the maximum number of threads that will concurrently perform a sub-compaction job by
## breaking it into multiple, smaller ones running simultaneously.
## The default value is set to 3 or the largest number to allow for two compactions, whichever is
## smaller.
max_subcompactions 4

## Number of open files that can be used by the DB.
## Value -1 means files opened are always kept open and RocksDB will prefetch index and filter
## blocks into block cache at startup. So if your database has a large working set, it will take
## several minutes to open the DB. You may need to increase this if your database has a large
## working set. You can estimate the number of files based on `target-file-size-base` and
## `target_file_size_multiplier` for level-based compaction.
max_open_files -1

#   Specify the maximal size of the info log file. If the log file
#   is larger than `max_log_file_size`, a new info log file will
#   be created.
#   If max_log_file_size == 0, all logs will be written to one
#   log file.
max_log_file_size 1073741824

## Max size of RocksDB's MANIFEST file.
## For detailed explanation, please refer to https://github.com/facebook/rocksdb/wiki/MANIFEST
max_manifest_file_size 134217728

#   By default, a single write thread queue is maintained. The thread gets
#   to the head of the queue becomes write batch group leader and responsible
#   for writing to WAL and memtable for the batch group.
#   If enable_pipelined_write is true, separate write thread queue is
#   maintained for WAL write and memtable write. A write thread first enter WAL
#   writer queue and then memtable writer queue. Pending thread on the WAL
#   writer queue thus only have to wait for previous writers to finish their
#   WAL writing but not the memtable writing. Enabling the feature may improve
#   write throughput and reduce latency of the prepare phase of two-phase
#   commit.
#   Default: false
enable_pipelined_write true

#   Setting unordered_write to true trades higher write throughput with
#   relaxing the immutability guarantee of snapshots. This violates the
#   repeatability one expects from ::Get from a snapshot, as well as
#   ::MultiGet and Iterator's consistent-point-in-time view property.
#   If the application cannot tolerate the relaxed guarantees, it can implement
#   its own mechanisms to work around that and yet benefit from the higher
#   throughput. Using TransactionDB with WRITE_PREPARED write policy and
#   two_write_queues=true is one way to achieve immutable snapshots despite
#   unordered_write.
#   By default, i.e., when it is false, rocksdb does not advance the sequence
#   number for new snapshots unless all the writes with lower sequence numbers
#   are already finished. This provides the immutability that we except from
#   snapshots. Moreover, since Iterator and MultiGet internally depend on
#   snapshots, the snapshot immutability results into Iterator and MultiGet
#   offering consistent-point-in-time view. If set to true, although
#   Read-Your-Own-Write property is still provided, the snapshot immutability
#   property is relaxed: the writes issued after the snapshot is obtained (with
#   larger sequence numbers) will be still not visible to the reads from that
#   snapshot, however, there still might be pending writes (with lower sequence
#   number) that will change the state visible to the snapshot after they are
#   landed to the memtable.
#   Default: false
#   Since RocksDB 6.3
#   !!! unordered_write is incompatible with enable_pipelined_write

unordered_write true

#   If enabled it uses two queues for writes, one for the ones with
#   disable_memtable and one for the ones that also write to memtable. This
#   allows the memtable writes not to lag behind other writes. It can be used
#   to optimize MySQL 2PC in which only the commits, which are serial, write to
#   memtable.
#   Since RocksDB 6.3

two_write_queues false